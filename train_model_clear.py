import os

# =========================================================
# [1. ì‹œìŠ¤í…œ ì„¤ì •] ë©ˆì¶¤ ë°©ì§€ ë° ì„±ëŠ¥ ìµœì í™” (ìµœìƒë‹¨ í•„ìˆ˜)
# =========================================================
os.environ["TORCH_Dynamo"] = "disable"
os.environ["TORCH_INDUCTOR"] = "0"
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"

import cv2
cv2.setNumThreads(0) # OpenCV ë©€í‹°ìŠ¤ë ˆë”© ì¶©ëŒ ë°©ì§€

import random
import numpy as np
import torch
import datetime
import json
import logging
import copy
from collections import defaultdict, OrderedDict
from tqdm import tqdm

# Detectron2 Imports
from detectron2.utils.logger import setup_logger
from detectron2.engine import DefaultTrainer, HookBase
from detectron2.config import get_cfg
from detectron2 import model_zoo
from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_train_loader, build_detection_test_loader
from detectron2.evaluation import COCOEvaluator, DatasetEvaluator, DatasetEvaluators
from detectron2.data import detection_utils as utils
from detectron2.data import transforms as T
from detectron2.checkpoint import DetectionCheckpointer
from detectron2.engine.hooks import BestCheckpointer
from detectron2.modeling import ROI_HEADS_REGISTRY, StandardROIHeads
from torch import nn
import torch.nn.functional as F
from detectron2.structures import BoxMode, pairwise_iou
import detectron2.utils.comm as comm

# =========================================================
# [ì„¤ì • ì˜ì—­] ì‚¬ìš©ì í™˜ê²½
# =========================================================

# [ë””ë²„ê¹… ì˜µì…˜]
# 0 ë˜ëŠ” None: ì „ì²´ ë°ì´í„° ì‚¬ìš© (ì‹¤ì „ í•™ìŠµ)
# ìˆ«ì (ì˜ˆ: 1000, 200): í•´ë‹¹ ê°œìˆ˜ë§Œí¼ë§Œ ìŠ¤ë§ˆíŠ¸í•˜ê²Œ ë½‘ì•„ì„œ ì‚¬ìš© (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
DEBUG_TRAIN_LIMIT = 0  # í•™ìŠµ ë£¨í”„ í™•ì¸ìš©
DEBUG_VAL_LIMIT = 0     # ê²€ì¦ ë° ì§€í‘œ ì¶œë ¥ í™•ì¸ìš©

# 1. í•™ìŠµ ë°ì´í„° (A: ê³ ì†ë„ë¡œ)
HWAY_TRAIN_JSON = '/home/elicer/data/090_AD_Hway_Day/Training/02_label_data/train_coco_with_distance.json'
HWAY_TRAIN_ROOT = '/home/elicer/data/090_AD_Hway_Day/Training/01_raw_data/image_data'

# 2. í•™ìŠµ ë°ì´í„° (B: ë„ì‹¬)
CITY_TRAIN_JSON = '/home/elicer/data/092_AD_City_Day/Training/02_label_data/label_day_clear/train_city_coco_with_dist.json'
CITY_TRAIN_ROOT = '/home/elicer/data/092_AD_City_Day/Training/01_raw_data/image_day_clear'

# 3. ê²€ì¦ ë°ì´í„°
VAL_JSON_PATH = '/home/elicer/data/090_AD_Hway_Day/Validation/integrated_val.json'
VAL_IMAGE_ROOT = None 

# 4. ì €ì¥ ê²½ë¡œ
OUTPUT_DIR = '/home/elicer/dev/gt/data/model/' + datetime.datetime.now().strftime("%Y%m%d_%H%M%S")

# =========================================================
# [3. ëª¨ë¸ ì •ì˜] Custom Head (Distance)
# =========================================================
@ROI_HEADS_REGISTRY.register()
class DistanceROIHeads(StandardROIHeads):
    def __init__(self, cfg, input_shape):
        super().__init__(cfg, input_shape)
        input_dim = self.box_head.output_shape.channels if hasattr(self.box_head, 'output_shape') else 1024
        self.distance_fc = nn.Sequential(nn.Linear(input_dim, 1), nn.ReLU())
        self.max_distance = 100.0

    def _forward_box(self, features, proposals):
        features_list = [features[f] for f in self.box_in_features]
        box_features = self.box_pooler(features_list, [x.proposal_boxes for x in proposals])
        box_features = self.box_head(box_features)
        pred_class_logits, pred_proposal_deltas = self.box_predictor(box_features)

        if self.training:
            pred_normalized = self.distance_fc(box_features)
            losses = self.box_predictor.losses((pred_class_logits, pred_proposal_deltas), proposals)
            losses["loss_distance"] = self._get_distance_loss(pred_normalized, proposals)
            return losses 
        else:
            pred_instances, _ = self.box_predictor.inference((pred_class_logits, pred_proposal_deltas), proposals)
            if len(pred_instances) == 0: return pred_instances
            
            pred_boxes = [x.pred_boxes for x in pred_instances]
            final_box_features = self.box_pooler(features_list, pred_boxes)
            final_box_features = self.box_head(final_box_features)
            
            pred_normalized = self.distance_fc(final_box_features)
            final_distances = pred_normalized * self.max_distance 
            
            start_idx = 0
            for instances in pred_instances:
                num_boxes = len(instances)
                instances.pred_distances = final_distances[start_idx : start_idx + num_boxes]
                start_idx += num_boxes
            return pred_instances

    def _get_distance_loss(self, pred_distances, proposals):
        gt_distances = []
        for p in proposals:
            if p.has("gt_distances"):
                gt_distances.append(p.gt_distances)
            else:
                gt_distances.append(torch.full((len(p),), -1.0, device=pred_distances.device))
        
        if not gt_distances: return pred_distances.sum() * 0
        gt_distances = torch.cat(gt_distances).flatten()
        pred_distances = pred_distances.flatten()
        valid_mask = (gt_distances > -0.5) 
        if valid_mask.sum() == 0: return pred_distances.sum() * 0
        
        loss = F.smooth_l1_loss(pred_distances[valid_mask], gt_distances[valid_mask], reduction='mean')
        return loss * 0.5

# =========================================================
# [4. í‰ê°€ ëª¨ë“ˆ] Rich Distance Evaluator
# =========================================================
class RichDistanceEvaluator(DatasetEvaluator):
    """ê±°ë¦¬ êµ¬ê°„ë³„ ì˜¤ì°¨(MAE) ë° ì „ì²´ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤."""
    def __init__(self, dataset_name, max_dist=100.0):
        self.dataset_name = dataset_name
        self.max_dist = max_dist
        self.reset()

    def reset(self):
        self.buckets = {"0-10m": [], "10-30m": [], "30-50m": [], "50m+": []}
        self.all_errors = []

    def process(self, inputs, outputs):
        for input, output in zip(inputs, outputs):
            pred = output["instances"].to("cpu")
            if not input.get("instances"): continue
            gt = input["instances"].to("cpu")
            
            if len(pred) == 0 or len(gt) == 0: continue
            
            ious = pairwise_iou(pred.pred_boxes, gt.gt_boxes)
            if ious.numel() == 0: continue
            matched_vals, matched_idxs = ious.max(dim=1)
            
            valid_mask = matched_vals > 0.5
            if valid_mask.sum() == 0: continue
            
            if not hasattr(pred, "pred_distances") or not hasattr(gt, "gt_distances"): continue
            
            pred_dists = pred.pred_distances[valid_mask]
            gt_idxs = matched_idxs[valid_mask]
            gt_dists = gt.gt_distances[gt_idxs]
            
            valid_gt_mask = gt_dists > -0.001 
            if valid_gt_mask.sum() == 0: continue
            
            p_d_m = pred_dists[valid_gt_mask].flatten()
            # GTëŠ” ë§¤í¼ì—ì„œ Normalize ë˜ì—ˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ ë³µì›í•´ì„œ ë¹„êµ (m ë‹¨ìœ„)
            g_d_m = gt_dists[valid_gt_mask].flatten() * self.max_dist
            
            abs_errs = torch.abs(p_d_m - g_d_m).tolist()
            gt_vals = g_d_m.tolist()
            
            for err, dist in zip(abs_errs, gt_vals):
                self.all_errors.append(err)
                if dist < 10: self.buckets["0-10m"].append(err)
                elif 10 <= dist < 30: self.buckets["10-30m"].append(err)
                elif 30 <= dist < 50: self.buckets["30-50m"].append(err)
                else: self.buckets["50m+"].append(err)

    def evaluate(self):
        results = OrderedDict()
        if self.all_errors:
            results["Total_MAE(m)"] = np.mean(self.all_errors)
        else:
            results["Total_MAE(m)"] = 0.0
            
        print("\n" + "="*40)
        print(" ğŸ“ Distance Prediction Analysis (MAE)")
        print("="*40)
        for range_name, errors in self.buckets.items():
            if len(errors) > 0:
                mae = np.mean(errors)
                count = len(errors)
                results[f"MAE_{range_name}"] = mae
                print(f"   Target {range_name:<7}: {mae:.2f}m  (Count: {count})")
            else:
                print(f"   Target {range_name:<7}: N/A    (Count: 0)")
        
        print(f"   [Total] Average: {results['Total_MAE(m)']:.2f}m")
        print("="*40 + "\n")
        return {"dist_metrics": results}

# =========================================================
# [5. ë°ì´í„° ë¡œë”©] ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§ & ê³ ì† íŒŒì‹±
# =========================================================

def get_custom_dicts_smart(json_path, image_root=None, dataset_name="", limit=0):
    print(f"ğŸ“‚ Loading {dataset_name}: {json_path}")
    
    # 1. JSON ë°ì´í„° ë¡œë“œ
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    categories = sorted(data['categories'], key=lambda x: x['id'])
    thing_classes = [c['name'] for c in categories]
    all_images = data['images']
    
    # 2. ì–´ë…¸í…Œì´ì…˜ ê³ ì† ì¸ë±ì‹± (ë¦¬ìŠ¤íŠ¸ ìˆœíšŒ X, ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ O)
    print(f"   -> Indexing annotations...")
    img_to_anns = defaultdict(list)
    cat_to_img_ids = defaultdict(set)
    
    for ann in data['annotations']:
        img_to_anns[ann['image_id']].append(ann)
        cat_to_img_ids[ann['category_id']].add(ann['image_id'])

    # 3. ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§ (ë””ë²„ê¹…ìš© ë°ì´í„° ì œí•œ ì‹œ)
    final_images = []
    
    if limit > 0 and limit < len(all_images):
        print(f"âš ï¸ [DEBUG] {dataset_name}: í´ë˜ìŠ¤ ê· í˜•ì„ ë§ì¶° {limit}ì¥ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
        selected_img_ids = set()
        MIN_PER_CLASS = 10 # ìµœì†Œ 10ì¥ì”©ì€ ë³´ì¥
        
        # í¬ê·€ í´ë˜ìŠ¤ë¶€í„° ìš°ì„  í™•ë³´
        sorted_cats = sorted(categories, key=lambda c: len(cat_to_img_ids[c['id']]))
        
        for cat in sorted_cats:
            cat_id = cat['id']
            candidates = list(cat_to_img_ids[cat_id])
            random.shuffle(candidates)
            
            count = 0
            for img_id in candidates:
                if count >= MIN_PER_CLASS: break
                if img_id not in selected_img_ids:
                    selected_img_ids.add(img_id)
                    count += 1
        
        # ë‚¨ì€ ê³µê°„ì€ ëœë¤ìœ¼ë¡œ ì±„ìš°ê¸°
        remaining_slots = limit - len(selected_img_ids)
        if remaining_slots > 0:
            all_ids = [img['id'] for img in all_images]
            random.shuffle(all_ids)
            for img_id in all_ids:
                if remaining_slots <= 0: break
                if img_id not in selected_img_ids:
                    selected_img_ids.add(img_id)
                    remaining_slots -= 1
        
        # ì„ íƒëœ IDë¡œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        img_lookup = {img['id']: img for img in all_images}
        final_images = [img_lookup[iid] for iid in selected_img_ids]
        print(f"   -> ê· í˜• ì¶”ì¶œ ì™„ë£Œ: {len(final_images)}ì¥")
        
    else:
        # ì œí•œ ì—†ìœ¼ë©´ ì „ì²´ ì‚¬ìš©
        final_images = all_images 

    # 4. ë°ì´í„°ì…‹ ë”•ì…”ë„ˆë¦¬ ìƒì„± (íŒŒì‹±)
    dataset_dicts = []
    missing_count = 0
    
    for img in tqdm(final_images, desc=f"Parsing {dataset_name}"):
        record = {}
        file_name = img['file_name']
        
        # ê²½ë¡œ ì²˜ë¦¬
        if os.path.isabs(file_name):
            full_path = file_name
        else:
            if image_root is None: continue
            full_path = os.path.join(image_root, file_name)
            
        # [ì•ˆì „ì¥ì¹˜] íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ (ì‚­ì œëœ ë°ì´í„° ê±´ë„ˆë›°ê¸°)
        if not os.path.exists(full_path):
            missing_count += 1
            continue
            
        record["file_name"] = full_path
        record["image_id"] = img['id']
        record["height"] = img['height']
        record["width"] = img['width']
        
        objs = []
        # ì¸ë±ì‹±ëœ ë”•ì…”ë„ˆë¦¬ì—ì„œ ì¦‰ì‹œ ì¡°íšŒ (O(1))
        current_anns = img_to_anns.get(img['id'], [])
        
        for ann in current_anns:
            dist_val = ann.get("distance", -1.0)
            if dist_val is None: dist_val = -1.0
            
            obj = {
                "bbox": ann["bbox"],
                "bbox_mode": BoxMode.XYWH_ABS, 
                "category_id": ann["category_id"] - 1, 
                "segmentation": ann.get("segmentation", []),
                "iscrowd": ann.get("iscrowd", 0),
                "distance": float(dist_val)
            }
            objs.append(obj)
        record["annotations"] = objs
        dataset_dicts.append(record)
    
    if missing_count > 0:
        print(f"âš ï¸ [Warning] {missing_count}ì¥ì˜ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê±´ë„ˆë›°ì—ˆìŠµë‹ˆë‹¤.")
    
    return dataset_dicts, thing_classes

# =========================================================
# [6. Mappers & Trainer]
# =========================================================
def train_mapper(dataset_dict):
    dataset_dict = copy.deepcopy(dataset_dict)
    try:
        # [í•µì‹¬] ì´ë¯¸ì§€ ì½ê¸° ì‹œë„
        image = utils.read_image(dataset_dict["file_name"], format="BGR")
    except Exception as e:
        # [ë°©ì–´] ì½ê¸° ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ë‚¨ê¸°ê³  None ë°˜í™˜ (ì•Œì•„ì„œ ê±´ë„ˆëœ€)
        print(f"\nâš ï¸ [Train Skip] ì´ë¯¸ì§€ ì†ìƒ/ë¡œë”© ì‹¤íŒ¨: {dataset_dict['file_name']} ({e})")
        return None

    # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (0ë°”ì´íŠ¸ íŒŒì¼ ë“± ë°©ì–´)
    if image is None or image.size == 0:
        print(f"\nâš ï¸ [Train Skip] ë¹ˆ ì´ë¯¸ì§€ íŒŒì¼: {dataset_dict['file_name']}")
        return None

    transform_list = [T.Resize((800, 800)), T.RandomFlip(prob=0.5)]
    image, transforms = T.apply_transform_gens(transform_list, image)
    dataset_dict["image"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))

    if "annotations" in dataset_dict:
        annos = [
            utils.transform_instance_annotations(obj, transforms, image.shape[:2])
            for obj in dataset_dict.pop("annotations")
            if obj.get("iscrowd", 0) == 0
        ]
        instances = utils.annotations_to_instances(annos, image.shape[:2])
        
        MAX_DIST = 100.0
        normalized_dists = []
        for obj in annos:
            d = obj.get("distance", -1.0)
            if d != -1.0: d = min(d, MAX_DIST) / MAX_DIST
            normalized_dists.append(d)
            
        instances.gt_distances = torch.tensor(normalized_dists, dtype=torch.float32)
        dataset_dict["instances"] = utils.filter_empty_instances(instances)
    
    return dataset_dict

def test_mapper(dataset_dict):
    """ê²€ì¦ìš© ë§¤í¼ (Augmentation ì—†ìŒ, GT í¬í•¨, ì—ëŸ¬ ë°©ì–´ í¬í•¨)"""
    dataset_dict = copy.deepcopy(dataset_dict)
    try:
        # [í•µì‹¬] ì´ë¯¸ì§€ ì½ê¸° ì‹œë„
        image = utils.read_image(dataset_dict["file_name"], format="BGR")
    except Exception as e:
        # [ë°©ì–´] ê²€ì¦ ë„ì¤‘ ë©ˆì¶”ì§€ ì•Šë„ë¡ Skip
        print(f"\nâš ï¸ [Val Skip] ì´ë¯¸ì§€ ì†ìƒ/ë¡œë”© ì‹¤íŒ¨: {dataset_dict['file_name']} ({e})")
        return None
    
    if image is None or image.size == 0:
        print(f"\nâš ï¸ [Val Skip] ë¹ˆ ì´ë¯¸ì§€ íŒŒì¼: {dataset_dict['file_name']}")
        return None
    
    # Resizeë§Œ (í•™ìŠµê³¼ ë™ì¼ ì¡°ê±´)
    transform_list = [T.Resize((800, 800))]
    image, transforms = T.apply_transform_gens(transform_list, image)
    dataset_dict["image"] = torch.as_tensor(np.ascontiguousarray(image.transpose(2, 0, 1)))

    if "annotations" in dataset_dict:
        annos = [
            utils.transform_instance_annotations(obj, transforms, image.shape[:2])
            for obj in dataset_dict.pop("annotations")
            if obj.get("iscrowd", 0) == 0
        ]
        instances = utils.annotations_to_instances(annos, image.shape[:2])
        
        MAX_DIST = 100.0
        normalized_dists = []
        for obj in annos:
            d = obj.get("distance", -1.0)
            if d != -1.0:
                d = min(d, MAX_DIST) / MAX_DIST
            normalized_dists.append(d)
            
        instances.gt_distances = torch.tensor(normalized_dists, dtype=torch.float32)
        dataset_dict["instances"] = instances
        
    return dataset_dict

class MyTrainer(DefaultTrainer):
    @classmethod
    def build_train_loader(cls, cfg):
        return build_detection_train_loader(cfg, mapper=train_mapper, num_workers=4)

    @classmethod
    def build_test_loader(cls, cfg, dataset_name):
        return build_detection_test_loader(cfg, dataset_name, mapper=test_mapper, num_workers=2)

    @classmethod
    def build_evaluator(cls, cfg, dataset_name, output_folder=None):
        if output_folder is None: output_folder = os.path.join(cfg.OUTPUT_DIR, "inference")
        return DatasetEvaluators([
            COCOEvaluator(dataset_name, output_dir=output_folder),
            RichDistanceEvaluator(dataset_name)
        ])
    
    def build_hooks(self):
        hooks = super().build_hooks()
        
        # 1. ê²€ì¦ ì‹¤í–‰ Hook (ì´ê²Œ ë¨¼ì € ìˆì–´ì•¼ ì ìˆ˜ê°€ ë‚˜ì˜´)
        hooks.insert(-1, ValidationLossHook(self.cfg))
        
        # 2. Best Model ì €ì¥ Hook
        hooks.append(BestCheckpointer(
            self.cfg.TEST.EVAL_PERIOD, 
            self.checkpointer, 
            "val_loss_distance", # ê°ì‹œí•  ì§€í‘œ
            "min",
            file_prefix="model_best_dist" 
        ))
        
        # 3. [ì¶”ê°€] Early Stopping Hook
        hooks.append(EarlyStoppingHook(
            patience=5,                 # 5ë²ˆ ì—°ì†ìœ¼ë¡œ ì•ˆ ì¢‹ì•„ì§€ë©´ ë©ˆì¶¤ (5 * 5000 iter = 25,000 iter ë™ì•ˆ)
            metric_name="val_loss_distance", # BestCheckpointerì™€ ê°™ì€ ì§€í‘œ ì¶”ì²œ
            mode="min",
            threshold=0.0001            # 0.0001ì´ë¼ë„ ì¤„ì–´ì•¼ ì¸ì •
        ))
        
        return hooks

class ValidationLossHook(HookBase):
    def __init__(self, cfg):
        super().__init__()
        self.cfg = cfg.clone()
        # Test Datasetìœ¼ë¡œ Validation Loss ê³„ì‚°
        self.cfg.DATASETS.TRAIN = self.cfg.DATASETS.TEST 
        self._loader = iter(build_detection_train_loader(self.cfg, mapper=test_mapper, num_workers=2))
        
    def after_step(self):
        if (self.trainer.iter + 1) % self.cfg.TEST.EVAL_PERIOD != 0: return
        try: 
            data = next(self._loader)
            if data is None: return
        except StopIteration:
            self._loader = iter(build_detection_train_loader(self.cfg, mapper=test_mapper, num_workers=2))
            data = next(self._loader)
        
        with torch.no_grad():
            self.trainer.model.train()
            loss_dict = self.trainer.model(data)
            loss_dict_reduced = {"val_" + k: v.item() for k, v in comm.reduce_dict(loss_dict).items()}
            if comm.is_main_process():
                self.trainer.storage.put_scalars(**loss_dict_reduced)

class EarlyStoppingHook(HookBase):
    def __init__(self, patience=5, metric_name="val_loss_distance", mode="min", threshold=0.0001):
        """
        Args:
            patience (int): ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë ¤ì¤„ íšŸìˆ˜ (ê²€ì¦ ì£¼ê¸° ê¸°ì¤€)
            metric_name (str): ê°ì‹œí•  ì§€í‘œ (ì˜ˆ: val_loss_distance, val_bbox_AP)
            mode (str): "min"ì´ë©´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ(Loss), "max"ë©´ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ(AP)
            threshold (float): ê°œì„ ìœ¼ë¡œ ê°„ì£¼í•  ìµœì†Œ ë³€í™”ëŸ‰
        """
        self.patience = patience
        self.metric_name = metric_name
        self.mode = mode
        self.threshold = threshold
        self.best_score = float("inf") if mode == "min" else float("-inf")
        self.wait_count = 0
        
    def after_step(self):
        # ê²€ì¦ ì£¼ê¸°(EVAL_PERIOD)ë§ˆë‹¤ ì²´í¬
        if (self.trainer.iter + 1) % self.trainer.cfg.TEST.EVAL_PERIOD != 0:
            return

        # Tensorboard/Storageì— ê¸°ë¡ëœ ìµœì‹  ì§€í‘œ ê°€ì ¸ì˜¤ê¸°
        storage = self.trainer.storage
        if self.metric_name not in storage.latest():
            return # ì•„ì§ ì§€í‘œê°€ ì—†ìœ¼ë©´ íŒ¨ìŠ¤

        # í˜„ì¬ ì ìˆ˜ (ì´ë™ í‰ê· ì´ ì•„ë‹Œ ìµœì‹  ê°’ ì‚¬ìš©)
        current_score = storage.latest()[self.metric_name][0]

        # ì„±ëŠ¥ ê°œì„  ì—¬ë¶€ íŒë‹¨
        improved = False
        if self.mode == "min":
            if current_score < self.best_score - self.threshold:
                improved = True
        else: # mode == "max"
            if current_score > self.best_score + self.threshold:
                improved = True

        if improved:
            self.best_score = current_score
            self.wait_count = 0 # ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
            # (ì˜µì…˜) ì—¬ê¸°ì„œ Best Modelì€ BestCheckpointerê°€ ì•Œì•„ì„œ ì €ì¥í•´ì¤Œ
        else:
            self.wait_count += 1
            print(f"\nâš ï¸ [EarlyStopping] {self.wait_count}/{self.patience} patience used. (Best: {self.best_score:.4f}, Curr: {current_score:.4f})")

        # ì¸ë‚´ì‹¬ ë°”ë‹¥ë‚¨ -> í•™ìŠµ ê°•ì œ ì¢…ë£Œ
        if self.wait_count >= self.patience:
            print(f"\nğŸ›‘ [EarlyStopping] Stopping training early! No improvement for {self.patience} evals.")
            self.trainer.storage.put_scalar("early_stop", 1) # ê¸°ë¡ìš©
            raise StopIteration # í•™ìŠµ ë£¨í”„ íƒˆì¶œ ì˜ˆì™¸ ë°œìƒ

# =========================================================
# [7. Main Execution]
# =========================================================
def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    setup_logger(output=OUTPUT_DIR) 
    
    print(">>> [1/4] Loading Datasets...")
    
    # 1. í•™ìŠµ ë°ì´í„° ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§)
    hway_dicts, classes = get_custom_dicts_smart(HWAY_TRAIN_JSON, HWAY_TRAIN_ROOT, "Highway", limit=DEBUG_TRAIN_LIMIT)
    city_dicts, _ = get_custom_dicts_smart(CITY_TRAIN_JSON, CITY_TRAIN_ROOT, "City", limit=DEBUG_TRAIN_LIMIT)
    total_train_dicts = hway_dicts + city_dicts
    
    DatasetCatalog.register("my_train", lambda: total_train_dicts)
    MetadataCatalog.get("my_train").set(thing_classes=classes)
    
    # 2. ê²€ì¦ ë°ì´í„° ë¡œë“œ (ìŠ¤ë§ˆíŠ¸ ìƒ˜í”Œë§)
    val_dicts, _ = get_custom_dicts_smart(VAL_JSON_PATH, image_root=None, dataset_name="Validation", limit=DEBUG_VAL_LIMIT)
    DatasetCatalog.register("my_val", lambda: val_dicts)
    MetadataCatalog.get("my_val").set(thing_classes=classes)
    
    print(f"âœ… Train: {len(total_train_dicts)} / Val: {len(val_dicts)}")

    print(">>> [2/4] Configuring Trainer...")
    cfg = get_cfg()
    cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
    
    cfg.DATASETS.TRAIN = ("my_train",)
    cfg.DATASETS.TEST = ("my_val",)
    cfg.DATALOADER.NUM_WORKERS = 6
    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")
    
    cfg.SOLVER.IMS_PER_BATCH = 8
    cfg.SOLVER.BASE_LR = 0.002
    
    # ë°˜ë³µ íšŸìˆ˜ ì„¤ì •
    if DEBUG_TRAIN_LIMIT > 0:
        cfg.SOLVER.MAX_ITER = DEBUG_TRAIN_LIMIT
        cfg.SOLVER.CHECKPOINT_PERIOD = 1000
        cfg.TEST.EVAL_PERIOD = 1000
    else:
        cfg.SOLVER.MAX_ITER = 40000
        cfg.SOLVER.STEPS = (28000, 36000)
        cfg.SOLVER.CHECKPOINT_PERIOD = 8000
        cfg.TEST.EVAL_PERIOD = 8000 
    
    cfg.MODEL.ROI_HEADS.NAME = "DistanceROIHeads"
    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(classes)
    cfg.OUTPUT_DIR = OUTPUT_DIR
    
    print(">>> [3/4] Starting Training...")
    trainer = MyTrainer(cfg) 
    trainer.register_hooks([ValidationLossHook(cfg)]) # Hook ì¶”ê°€ ë°©ì‹ ë³€ê²½ (ëª…ì‹œì  ë“±ë¡)
    trainer.resume_or_load(resume=False)
    trainer.train()

if __name__ == "__main__":
    main()